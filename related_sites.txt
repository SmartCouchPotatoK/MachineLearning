

< Pandas memory usage >
https://towardsdatascience.com/why-and-how-to-use-pandas-with-large-data-9594dda2ea4c
https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html
https://www.dataquest.io/blog/pandas-big-data/
https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2

< Visualization - Bokeh > 
https://www.kaggle.com/pavansanagapati/pandas-bokeh-visualization-tutorial


< Feature Selection & Engineering > 
https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering
https://www.kaggle.com/willkoehrsen/introduction-to-feature-selection

https://www.kaggle.com/sz8416/6-ways-for-feature-selection
https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection

1) https://wikidocs.net/26408 : PPT참고
2) https://itchipmunk.tistory.com/194 : PPT참고
3) https://woolulu.tistory.com/category/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%91%9C%ED%98%84%EA%B3%BC%20%ED%8A%B9%EC%84%B1/feature%20auto-selection (2와비슷)
4) https://data-newbie.tistory.com/27 (2와비슷)

원핫인코딩은 전체데이터를 바라보고 해야한다.
그런데 이렇게 만들어서 f(x)를 만들었는데 추후에 새로운 범주가 들어봐 버린다면?
연속형을 구간분할하여 범주형으로 만들기 : np.digitize 이용


** 추가 (우선순위 높음) **
https://www.kaggle.com/arthurtok/feature-ranking-rfe-random-forest-linear-models :: 뭔가 내가 찾는 5가지 방법비교
https://www.kaggle.com/matleonard/feature-selection :: L1 regularization 참고
https://www.kaggle.com/prashant111/comprehensive-guide-on-feature-selection :: BIBLE 느낌
https://www.kaggle.com/harangdev/feature-selection :: one-shot vs RFE
https://www.kaggle.com/mashimo/features-selection-for-multiple-linear-regression :: statsmodel (MLR 해석)



